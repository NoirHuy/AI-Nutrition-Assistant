from groq import Groq
from app.config import settings
from app.services.graph_query import get_dietary_advice, get_food_nutrients

# K·∫øt n·ªëi Client
client = None
try:
    if settings.GROQ_API_KEY:
        client = Groq(api_key=settings.GROQ_API_KEY)
except Exception as e:
    print(f"‚ùå L·ªói Config AI: {e}")

# --- VISION: D√ôNG LLAMA-4 MAVERICK ---
def identify_food_name(image_base64: str):
    # Prompt ng·∫Øn g·ªçn ƒë·ªÉ l·∫•y t√™n m√≥n
    prompt = "ƒê√¢y l√† m√≥n ƒÉn g√¨ c·ªßa Vi·ªát Nam? Ch·ªâ tr·∫£ l·ªùi ng·∫Øn g·ªçn t√™n m√≥n. V√≠ d·ª•: Ph·ªü b√≤"
    
    try:
        completion = client.chat.completions.create(
            # üëá MODEL 1: THEO Y√äU C·∫¶U C·ª¶A B·∫†N
            model="meta-llama/llama-4-maverick-17b-128e-instruct",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}}
                    ]
                }
            ],
            temperature=0.2, 
            max_completion_tokens=50
        )
        return completion.choices[0].message.content.strip()
    except Exception as e:
        print(f"‚ùå L·ªói Vision: {e}")
        return None

# --- REASONING: D√ôNG GPT-OSS-120B ---
def generate_medical_advice(food_name: str, disease: str):
    # 1. L·∫•y d·ªØ li·ªáu t·ª´ Graph
    disease_data = get_dietary_advice(disease)
    food_graph_data = get_food_nutrients(food_name)
    
    # 2. Chu·∫©n b·ªã ng·ªØ c·∫£nh
    context = f"B·ªánh nh√¢n b·ªã: {disease}."
    if disease_data:
        context += f"\n- QUY T·∫ÆC C·∫§M (T·ª´ Graph): {', '.join(disease_data['avoid_nutrients'])}"
    
    food_info = f"M√≥n ƒÉn: {food_name}"
    
    # ∆Øu ti√™n d·ªØ li·ªáu Graph n·∫øu c√≥
    if food_graph_data:
        food_info += f"\n(D·ªÆ LI·ªÜU G·ªêC T·ª™ GRAPH - ∆ØU TI√äN S·ªê 1)"
        food_info += f"\n- T√™n chu·∫©n: {food_graph_data['found_name']}"
        food_info += f"\n- Th√†nh ph·∫ßn dinh d∆∞·ª°ng: {', '.join([n['name'] for n in food_graph_data['ingredients']])}"
    else:
        food_info += "\n(M√≥n n√†y ch∆∞a c√≥ trong Graph, h√£y t·ª± ∆∞·ªõc l∆∞·ª£ng)."

    # 3. Prompt T∆∞ v·∫•n
    system_prompt = f"""
    B·∫°n l√† Tr·ª£ l√Ω Dinh d∆∞·ª°ng AI.
    
    D·ªÆ LI·ªÜU ƒê·∫¶U V√ÄO:
    {context}
    {food_info}
    
    Y√äU C·∫¶U:
    - N·∫øu c√≥ d·ªØ li·ªáu Graph, h√£y ƒëi·ªÅn ch√≠nh x√°c v√†o b·∫£ng.
    - So s√°nh th√†nh ph·∫ßn v·ªõi "QUY T·∫ÆC C·∫§M". N·∫øu tr√πng -> Ghi "‚ö†Ô∏è VI PH·∫†M".
    
    FORMAT TR·∫¢ L·ªúI (Markdown):
    ## üç≤ K·∫øt qu·∫£: {food_name}
    | Th√†nh ph·∫ßn | ƒê√°nh gi√° |
    |---|---|
    | ... | ... |
    **L·ªùi khuy√™n:** ...
    """

    try:
        completion = client.chat.completions.create(
            # üëá MODEL 2: THEO Y√äU C·∫¶U C·ª¶A B·∫†N
            model="openai/gpt-oss-120b", 
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": "Ph√¢n t√≠ch ngay."}
            ],
            temperature=0.3
        )
        return completion.choices[0].message.content
    except Exception as e:
        return f"L·ªói T∆∞ v·∫•n: {e}"

# --- MAIN ENTRY ---
def analyze_image_diet(image_base64: str, disease: str):
    if not client: return "L·ªói Server: Ch∆∞a c√≥ Key AI."
    
    # B1: G·ªçi Llama-4 Maverick
    detected_name = identify_food_name(image_base64)
    if not detected_name:
        return "‚ö†Ô∏è Kh√¥ng nh√¨n r√µ ·∫£nh. Vui l√≤ng ch·ª•p l·∫°i ho·∫∑c nh·∫≠p t√™n m√≥n."
    
    # B2: G·ªçi GPT-OSS-120B
    return generate_medical_advice(detected_name, disease)

def generate_response(user_text: str, disease: str):
    return generate_medical_advice(user_text, disease)